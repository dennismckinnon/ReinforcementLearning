{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole: A Comparison\n",
    "This Mini-project's goal is to apply Deep Reinforcement Learning techniques to the Cart-Pole environment. We will implement DQN (REF) as well as improvements Double DQN, and Dueling DQN. The performance of all three will be compared on cartpole. This will hopefully act as a test bed for understanding various improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open AI Gym\n",
    "First I want to import Open AI gym and test that the cartpole environment will work. I will play a game with the policy that the left action will be chosen whenever the velocity of the pole is to the right and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    # This policy looks at the angular velocity (state[3]) and applies force in the opposite direction.\n",
    "    # It is by no means a perfect policy but it is a decent test to ensure its working as expected\n",
    "    action = 0 if (state[3] < 0) else 1\n",
    "    state, reward, done, info = env.step(action)\n",
    "    \n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q Learning (DQN)\n",
    "The agent below implements DQN as presented in [REF]. Since CartPole is a simple game, The network will be implemented with only 2 hidden layers. The orignal DQN paper introduced two key ideas. 1) The replay-buffer which records (S,A,R,S') experiences and 2) The target of the Q learning (approximation of true Q value) is held fixed and periodically updated.\n",
    "\n",
    "In order to implement 2) we need to create two identical networks and then copy operations for moving the parameters from one to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replay Buffer Class by David Kroezen\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "\n",
    "    num_state = 3\n",
    "    \n",
    "    def __init__(self, buffer_size):\n",
    "        \" Initializes the replay buffer by creating a deque() and setting the size and buffer count. \"\n",
    "        self.buffer = deque()\n",
    "        self.buffer_size = buffer_size\n",
    "        self.count = 0\n",
    "         \n",
    "    def add(self, s, a, r, d, s2):\n",
    "         \n",
    "        \"\"\" Adds new experience to the ReplayBuffer(). If the buffer size is\n",
    "        reached, the oldest item is removed.\n",
    "         \n",
    "        Inputs needed to create new experience:\n",
    "            s      - State\n",
    "            a      - Action\n",
    "            r      - Reward\n",
    "            d      - Done\n",
    "            s2     - Resulting State     \n",
    "        \"\"\"\n",
    "        d = 1 if d else 0\n",
    "        # Create experience list\n",
    "        experience = (s, a, r, d, s2)\n",
    "        \n",
    "        # Check the size of the buffer\n",
    "        if self.count < self.buffer_size:\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.buffer.popleft()\n",
    "            \n",
    "        # Add experience to buffer\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def size(self):\n",
    "        \" Return the amount of stored experiences. \" \n",
    "        return self.count\n",
    "    \n",
    "    def batch(self, batch_size):\n",
    "        \"Return a \\\"batch_size\\\" number of random samples from the buffer.\"\n",
    "        \n",
    "        if self.count < batch_size:\n",
    "            batch = random.sample(self.buffer, self.count)\n",
    "            batch_size = self.count\n",
    "        else:\n",
    "            batch = random.sample(self.buffer, batch_size)\n",
    "            \n",
    "        batch_state = np.array([item[0] for item in batch])#.reshape([batch_size,self.num_state])\n",
    "        batch_action = np.array([item[1] for item in batch])#.reshape([batch_size, 1])\n",
    "        batch_reward = np.array([item[2] for item in batch])#.reshape([batch_size, 1])\n",
    "        batch_done = np.array([item[3] for item in batch])#.reshape([batch_size, 1])\n",
    "        batch_next_state = np.array([item[4] for item in batch])#.reshape([batch_size,self.num_state])\n",
    "        \n",
    "        return batch_state, batch_action, batch_reward, batch_done, batch_next_state \n",
    "            \n",
    "    def clear(self):\n",
    "        \" Remove all entries from the ReplayBuffer. \"\n",
    "        self.buffer.clear()\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def makeDQN(state, h_size, a_size, name):\n",
    "#     # Make a network\n",
    "#     with tf.variable_scope(name):\n",
    "#         h1 = tf.nn.relu(tf.layers.dense(state, h_size))\n",
    "#         h2 = tf.nn.relu(tf.layers.dense(h1, h_size))\n",
    "#         out = tf.layers.dense(h2, a_size)\n",
    "#     return out\n",
    "\n",
    "def makeDQN(state, h_size, a_size, name):\n",
    "    # Make a network\n",
    "    with tf.variable_scope(name):\n",
    "        h1 = tf.contrib.layers.fully_connected(state, h_size)\n",
    "        h2 = tf.contrib.layers.fully_connected(h1, h_size)\n",
    "        out = tf.contrib.layers.fully_connected(h2, a_size, activation_fn=None)\n",
    "    return out\n",
    "\n",
    "def copyVars(fromName, toName):\n",
    "    # Constructs the copy operations\n",
    "    fvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=fromName)\n",
    "    tvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=toName)\n",
    "    \n",
    "    copy = [tf.assign(t, f) for f, t in zip(fvars, tvars)]\n",
    "    return copy\n",
    "    \n",
    "\n",
    "class DQN():\n",
    "    def __init__(self, sess, e_size, h_size, a_size, lr=0.01, gamma=0.99, replay_length=10000, batch_size=64):\n",
    "        \n",
    "        # Store params\n",
    "        self.batch_size = batch_size\n",
    "        self.replay_length = replay_length\n",
    "        self.sess = sess\n",
    "        \n",
    "        # Define Inputs\n",
    "        self.state = tf.placeholder(tf.float32, shape=[None, e_size], name='State_input')\n",
    "        self.actions = tf.placeholder(tf.int32, shape=[None], name='actions')\n",
    "        self.rewards = tf.placeholder(tf.float32, shape=[None], name='rewards')\n",
    "        self.dones = tf.placeholder(tf.float32, shape=[None], name='dones')\n",
    "        self.next_state = tf.placeholder(tf.float32, shape=[None, e_size], name='Next_State_input')\n",
    "        self.targetQ = tf.placeholder(tf.float32, shape=[None], name='QTargets')\n",
    "        self.gamma = tf.placeholder(tf.float32, name='Gamma')\n",
    "#         self.learning_rate = tf.placeholder(tf.float32)\n",
    "        \n",
    "        # Define Network\n",
    "        self.main = makeDQN(self.state, h_size, a_size, 'main')\n",
    "        self.target = makeDQN(self.next_state, h_size, a_size, 'target')\n",
    "        \n",
    "        # Create the update operations for updating the target network\n",
    "        self.copy = copyVars('main', 'target')\n",
    "        \n",
    "        # Define the Loss operation \n",
    "        # Inline with the udacity implementation I am splitting the target generation operation from\n",
    "        # The whole computation graph. I'm also using self.main now instead of self.target\n",
    "        self.makeTargets = self.rewards + self.gamma*(tf.ones_like(self.dones)-self.dones)*tf.reduce_max(self.main, axis=1)\n",
    "        print (self.makeTargets)\n",
    "        choice = tf.one_hot(self.actions, a_size)\n",
    "        print (self.main)\n",
    "        print (choice)\n",
    "        self.predictedQ = tf.reduce_sum(self.main*choice, axis=1)\n",
    "        print (self.predictedQ)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.targetQ-self.predictedQ))\n",
    "        \n",
    "        # Optimizer\n",
    "        # Restrict training to the main network\n",
    "        tvars = tf.trainable_variables(scope='main')\n",
    "        self.optimize = tf.train.AdamOptimizer(lr).minimize(self.loss)#, var_list=tvars)\n",
    "        \n",
    "        # Helper ops\n",
    "        self.choice = tf.argmax(self.main, 1)\n",
    "        self.choice_prob = tf.nn.softmax(self.main)\n",
    "        \n",
    "        \n",
    "        # Set up experience replay buffer\n",
    "        self.replay = ReplayBuffer(replay_length)\n",
    "        \n",
    "    def train(self, gamma=0.99):\n",
    "        # Get a batch of experiences\n",
    "        states, actions, rewards, dones, next_states = self.replay.batch(self.batch_size)\n",
    "        targets = self.sess.run(self.makeTargets, feed_dict={self.state: next_states,\n",
    "                                                             self.rewards: rewards,\n",
    "                                                             self.dones: dones,\n",
    "                                                             self.gamma: gamma})\n",
    "        predicted = self.sess.run(self.predictedQ, feed_dict={self.state: states,\n",
    "                                                self.actions: actions})\n",
    "#         print (\"=========================\")\n",
    "#         print (targets)\n",
    "#         print (predicted)\n",
    "        Qs = self.sess.run(self.main, feed_dict={self.state: states})\n",
    "#         print (Qs)\n",
    "        self.sess.run(self.optimize, feed_dict={self.state: states,\n",
    "                                                self.actions: actions,\n",
    "                                                self.targetQ: targets})\n",
    "    def clean_state(self, s):\n",
    "        # This really SHOULD convert to a numpy array also\n",
    "        if (len(s.shape)==1):\n",
    "            s = s[None, :]\n",
    "        return s\n",
    "    \n",
    "    def remember(self, state, action, reward, done, next_state):\n",
    "        self.replay.add(state, action, reward, done, next_state)\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        Qs = self.sess.run(self.main, feed_dict={self.state: self.clean_state(state)})\n",
    "        action = self.sess.run(self.choice, feed_dict={self.state: self.clean_state(state)})\n",
    "#         print (\"=====================\")\n",
    "#         print (Qs)\n",
    "#         print (action)\n",
    "        return action[0]\n",
    "        \n",
    "    \n",
    "    def choose_probs(self, state):\n",
    "        return self.sess.run(self.choice_prob, feed_dict={self.state: self.clean_state(state)})\n",
    "    \n",
    "    def update_target(self):\n",
    "#         print (self.sess.run(self.main, feed_dict={self.state:[[0.01,0.01,0.01,0.01]]}))\n",
    "#         print (self.sess.run(self.target, feed_dict={self.next_state:[[0.01,0.01,0.01,0.01]]}))\n",
    "        self.sess.run(self.copy)\n",
    "#         print (self.sess.run(self.target, feed_dict={self.next_state:[[0.01,0.01,0.01,0.01]]}))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running DQN\n",
    "With the agent defined its time to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", dtype=float32)\n",
      "Tensor(\"main/fully_connected_2/BiasAdd:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"one_hot:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"Sum:0\", shape=(?,), dtype=float32)\n",
      "Round:       0 \tEpsilon:  1.00 \tTest Score:   11.66\n",
      "Round:       1 \tEpsilon:  1.00 \tTest Score:   13.94\n",
      "Round:       2 \tEpsilon:  1.00 \tTest Score:   19.31\n",
      "Round:       3 \tEpsilon:  0.99 \tTest Score:   26.69\n",
      "Round:       4 \tEpsilon:  0.99 \tTest Score:   24.53\n",
      "Round:       5 \tEpsilon:  0.99 \tTest Score:   23.19\n",
      "Round:       6 \tEpsilon:  0.99 \tTest Score:   21.16\n",
      "Round:       7 \tEpsilon:  0.99 \tTest Score:   13.00\n",
      "Round:       8 \tEpsilon:  0.98 \tTest Score:   18.25\n",
      "Round:       9 \tEpsilon:  0.98 \tTest Score:   17.62\n",
      "Round:      10 \tEpsilon:  0.98 \tTest Score:   16.44\n",
      "Round:      11 \tEpsilon:  0.98 \tTest Score:   14.59\n",
      "Round:      12 \tEpsilon:  0.98 \tTest Score:   18.12\n",
      "Round:      13 \tEpsilon:  0.97 \tTest Score:   16.25\n",
      "Round:      14 \tEpsilon:  0.97 \tTest Score:   19.31\n",
      "Round:      15 \tEpsilon:  0.97 \tTest Score:   15.09\n",
      "Round:      16 \tEpsilon:  0.97 \tTest Score:   13.31\n",
      "Round:      17 \tEpsilon:  0.97 \tTest Score:   10.81\n",
      "Round:      18 \tEpsilon:  0.97 \tTest Score:   10.34\n",
      "Round:      19 \tEpsilon:  0.96 \tTest Score:    9.72\n",
      "Round:      20 \tEpsilon:  0.96 \tTest Score:   10.22\n",
      "Round:      21 \tEpsilon:  0.95 \tTest Score:   10.78\n",
      "Round:      22 \tEpsilon:  0.95 \tTest Score:   10.06\n",
      "Round:      23 \tEpsilon:  0.95 \tTest Score:    9.47\n",
      "Round:      24 \tEpsilon:  0.95 \tTest Score:    9.72\n",
      "Round:      25 \tEpsilon:  0.95 \tTest Score:   10.50\n",
      "Round:      26 \tEpsilon:  0.95 \tTest Score:   11.22\n",
      "Round:      27 \tEpsilon:  0.94 \tTest Score:   10.84\n",
      "Round:      28 \tEpsilon:  0.94 \tTest Score:   10.66\n",
      "Round:      29 \tEpsilon:  0.94 \tTest Score:   11.25\n",
      "Round:      30 \tEpsilon:  0.94 \tTest Score:   12.25\n",
      "Round:      31 \tEpsilon:  0.94 \tTest Score:   13.12\n",
      "Round:      32 \tEpsilon:  0.94 \tTest Score:   11.69\n",
      "Round:      33 \tEpsilon:  0.93 \tTest Score:   10.97\n",
      "Round:      34 \tEpsilon:  0.93 \tTest Score:   14.47\n",
      "Round:      35 \tEpsilon:  0.93 \tTest Score:   15.22\n",
      "Round:      36 \tEpsilon:  0.92 \tTest Score:   12.31\n",
      "Round:      37 \tEpsilon:  0.92 \tTest Score:   12.66\n",
      "Round:      38 \tEpsilon:  0.92 \tTest Score:   11.34\n",
      "Round:      39 \tEpsilon:  0.92 \tTest Score:   10.56\n",
      "Round:      40 \tEpsilon:  0.92 \tTest Score:   10.25\n",
      "Round:      41 \tEpsilon:  0.91 \tTest Score:   11.72\n",
      "Round:      42 \tEpsilon:  0.91 \tTest Score:   12.56\n",
      "Round:      43 \tEpsilon:  0.91 \tTest Score:   13.31\n",
      "Round:      44 \tEpsilon:  0.91 \tTest Score:   12.72\n",
      "Activate!\n",
      "Round:      45 \tEpsilon:  0.90 \tTest Score:   13.47\n",
      "Round:      46 \tEpsilon:  0.90 \tTest Score:    9.25\n",
      "Round:      47 \tEpsilon:  0.90 \tTest Score:    9.34\n",
      "Round:      48 \tEpsilon:  0.90 \tTest Score:    9.28\n",
      "Round:      49 \tEpsilon:  0.90 \tTest Score:    9.19\n",
      "Round:      50 \tEpsilon:  0.89 \tTest Score:    9.19\n",
      "Round:      51 \tEpsilon:  0.89 \tTest Score:    9.34\n",
      "Round:      52 \tEpsilon:  0.89 \tTest Score:    9.50\n",
      "Round:      53 \tEpsilon:  0.89 \tTest Score:    9.44\n",
      "Round:      54 \tEpsilon:  0.88 \tTest Score:    9.56\n",
      "Round:      55 \tEpsilon:  0.88 \tTest Score:    9.44\n",
      "Round:      56 \tEpsilon:  0.88 \tTest Score:    9.66\n",
      "Round:      57 \tEpsilon:  0.88 \tTest Score:    9.19\n",
      "Round:      58 \tEpsilon:  0.88 \tTest Score:    9.19\n",
      "Round:      59 \tEpsilon:  0.88 \tTest Score:    9.28\n",
      "Round:      60 \tEpsilon:  0.87 \tTest Score:    9.34\n",
      "Round:      61 \tEpsilon:  0.87 \tTest Score:    9.25\n",
      "Round:      62 \tEpsilon:  0.87 \tTest Score:    9.50\n",
      "Round:      63 \tEpsilon:  0.87 \tTest Score:    9.56\n",
      "Round:      64 \tEpsilon:  0.87 \tTest Score:    9.47\n",
      "Round:      65 \tEpsilon:  0.87 \tTest Score:    9.38\n",
      "Round:      66 \tEpsilon:  0.87 \tTest Score:    9.34\n",
      "Round:      67 \tEpsilon:  0.86 \tTest Score:    9.41\n",
      "Round:      68 \tEpsilon:  0.86 \tTest Score:    9.38\n",
      "Round:      69 \tEpsilon:  0.86 \tTest Score:    9.25\n",
      "Round:      70 \tEpsilon:  0.86 \tTest Score:    9.12\n",
      "Round:      71 \tEpsilon:  0.86 \tTest Score:    9.38\n",
      "Round:      72 \tEpsilon:  0.85 \tTest Score:    9.22\n",
      "Round:      73 \tEpsilon:  0.85 \tTest Score:    9.44\n",
      "Round:      74 \tEpsilon:  0.85 \tTest Score:    9.38\n",
      "Round:      75 \tEpsilon:  0.85 \tTest Score:    9.28\n",
      "Round:      76 \tEpsilon:  0.85 \tTest Score:    9.44\n",
      "Round:      77 \tEpsilon:  0.84 \tTest Score:    9.56\n",
      "Round:      78 \tEpsilon:  0.84 \tTest Score:    9.38\n",
      "Round:      79 \tEpsilon:  0.84 \tTest Score:    9.38\n",
      "Round:      80 \tEpsilon:  0.84 \tTest Score:    9.25\n",
      "Round:      81 \tEpsilon:  0.84 \tTest Score:    9.34\n",
      "Round:      82 \tEpsilon:  0.84 \tTest Score:    9.53\n",
      "Round:      83 \tEpsilon:  0.83 \tTest Score:    9.44\n",
      "Round:      84 \tEpsilon:  0.83 \tTest Score:    9.50\n",
      "Round:      85 \tEpsilon:  0.83 \tTest Score:    9.31\n",
      "Round:      86 \tEpsilon:  0.83 \tTest Score:    9.19\n",
      "Round:      87 \tEpsilon:  0.83 \tTest Score:    9.19\n",
      "Round:      88 \tEpsilon:  0.83 \tTest Score:    9.44\n",
      "Round:      89 \tEpsilon:  0.82 \tTest Score:    9.50\n",
      "Round:      90 \tEpsilon:  0.82 \tTest Score:    9.22\n",
      "Round:      91 \tEpsilon:  0.82 \tTest Score:    9.47\n",
      "Round:      92 \tEpsilon:  0.82 \tTest Score:    9.38\n",
      "Round:      93 \tEpsilon:  0.82 \tTest Score:    9.53\n",
      "Round:      94 \tEpsilon:  0.82 \tTest Score:    9.53\n",
      "Round:      95 \tEpsilon:  0.82 \tTest Score:    9.50\n",
      "Round:      96 \tEpsilon:  0.81 \tTest Score:    9.59\n",
      "Round:      97 \tEpsilon:  0.81 \tTest Score:    9.28\n",
      "Round:      98 \tEpsilon:  0.81 \tTest Score:    9.22\n",
      "Round:      99 \tEpsilon:  0.81 \tTest Score:    9.34\n",
      "Round:     100 \tEpsilon:  0.80 \tTest Score:    9.50\n",
      "Round:     101 \tEpsilon:  0.80 \tTest Score:    9.31\n",
      "Round:     102 \tEpsilon:  0.80 \tTest Score:    9.56\n",
      "Round:     103 \tEpsilon:  0.80 \tTest Score:    9.44\n",
      "Round:     104 \tEpsilon:  0.80 \tTest Score:    9.31\n",
      "Round:     105 \tEpsilon:  0.80 \tTest Score:    9.16\n",
      "Round:     106 \tEpsilon:  0.79 \tTest Score:    9.47\n",
      "Round:     107 \tEpsilon:  0.79 \tTest Score:    9.66\n",
      "Round:     108 \tEpsilon:  0.79 \tTest Score:    9.56\n",
      "Round:     109 \tEpsilon:  0.79 \tTest Score:    9.47\n",
      "Round:     110 \tEpsilon:  0.79 \tTest Score:    9.12\n",
      "Round:     111 \tEpsilon:  0.78 \tTest Score:    9.38\n",
      "Round:     112 \tEpsilon:  0.78 \tTest Score:    9.34\n",
      "Round:     113 \tEpsilon:  0.78 \tTest Score:    9.34\n",
      "Round:     114 \tEpsilon:  0.78 \tTest Score:    9.44\n",
      "Round:     115 \tEpsilon:  0.78 \tTest Score:    9.44\n",
      "Round:     116 \tEpsilon:  0.78 \tTest Score:    9.34\n",
      "Round:     117 \tEpsilon:  0.78 \tTest Score:    9.38\n",
      "Round:     118 \tEpsilon:  0.78 \tTest Score:    9.34\n",
      "Round:     119 \tEpsilon:  0.78 \tTest Score:    9.31\n",
      "Round:     120 \tEpsilon:  0.77 \tTest Score:    9.41\n",
      "Round:     121 \tEpsilon:  0.77 \tTest Score:    9.38\n",
      "Round:     122 \tEpsilon:  0.77 \tTest Score:    9.72\n",
      "Round:     123 \tEpsilon:  0.77 \tTest Score:    9.94\n",
      "Round:     124 \tEpsilon:  0.77 \tTest Score:   10.62\n",
      "Round:     125 \tEpsilon:  0.77 \tTest Score:   10.38\n",
      "Round:     126 \tEpsilon:  0.77 \tTest Score:   10.81\n",
      "Round:     127 \tEpsilon:  0.76 \tTest Score:   14.91\n",
      "Round:     128 \tEpsilon:  0.76 \tTest Score:   17.47\n",
      "Round:     129 \tEpsilon:  0.76 \tTest Score:   42.56\n",
      "Round:     130 \tEpsilon:  0.76 \tTest Score:   14.47\n",
      "Round:     131 \tEpsilon:  0.76 \tTest Score:   11.81\n",
      "Round:     132 \tEpsilon:  0.76 \tTest Score:    9.28\n",
      "Round:     133 \tEpsilon:  0.75 \tTest Score:    9.31\n",
      "Round:     134 \tEpsilon:  0.75 \tTest Score:    9.31\n",
      "Round:     135 \tEpsilon:  0.75 \tTest Score:    9.25\n",
      "Round:     136 \tEpsilon:  0.75 \tTest Score:    9.38\n",
      "Round:     137 \tEpsilon:  0.75 \tTest Score:    9.50\n",
      "Round:     138 \tEpsilon:  0.75 \tTest Score:    9.56\n",
      "Round:     139 \tEpsilon:  0.75 \tTest Score:    9.47\n",
      "Round:     140 \tEpsilon:  0.74 \tTest Score:    9.41\n",
      "Round:     141 \tEpsilon:  0.74 \tTest Score:    9.19\n",
      "Round:     142 \tEpsilon:  0.74 \tTest Score:    9.38\n",
      "Round:     143 \tEpsilon:  0.74 \tTest Score:    9.31\n",
      "Round:     144 \tEpsilon:  0.74 \tTest Score:    9.31\n",
      "Round:     145 \tEpsilon:  0.74 \tTest Score:    9.06\n",
      "Round:     146 \tEpsilon:  0.74 \tTest Score:    9.53\n",
      "Round:     147 \tEpsilon:  0.74 \tTest Score:    9.34\n",
      "Round:     148 \tEpsilon:  0.73 \tTest Score:    9.50\n",
      "Round:     149 \tEpsilon:  0.73 \tTest Score:    9.41\n",
      "Round:     150 \tEpsilon:  0.73 \tTest Score:    9.53\n",
      "Round:     151 \tEpsilon:  0.73 \tTest Score:    9.31\n",
      "Round:     152 \tEpsilon:  0.73 \tTest Score:    9.31\n",
      "Round:     153 \tEpsilon:  0.73 \tTest Score:    9.44\n",
      "Round:     154 \tEpsilon:  0.73 \tTest Score:    9.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:     155 \tEpsilon:  0.72 \tTest Score:    9.25\n",
      "Round:     156 \tEpsilon:  0.72 \tTest Score:    9.12\n",
      "Round:     157 \tEpsilon:  0.72 \tTest Score:    9.41\n",
      "Round:     158 \tEpsilon:  0.72 \tTest Score:    9.19\n",
      "Round:     159 \tEpsilon:  0.72 \tTest Score:    9.25\n",
      "Round:     160 \tEpsilon:  0.72 \tTest Score:    9.34\n",
      "Round:     161 \tEpsilon:  0.72 \tTest Score:    9.31\n",
      "Round:     162 \tEpsilon:  0.72 \tTest Score:    9.38\n",
      "Round:     163 \tEpsilon:  0.71 \tTest Score:    9.28\n",
      "Round:     164 \tEpsilon:  0.71 \tTest Score:    9.38\n",
      "Round:     165 \tEpsilon:  0.71 \tTest Score:    9.16\n",
      "Round:     166 \tEpsilon:  0.71 \tTest Score:    9.44\n",
      "Round:     167 \tEpsilon:  0.71 \tTest Score:    9.34\n",
      "Round:     168 \tEpsilon:  0.71 \tTest Score:    9.41\n",
      "Round:     169 \tEpsilon:  0.71 \tTest Score:    9.34\n",
      "Round:     170 \tEpsilon:  0.70 \tTest Score:    9.03\n",
      "Round:     171 \tEpsilon:  0.70 \tTest Score:    9.50\n",
      "Round:     172 \tEpsilon:  0.70 \tTest Score:    9.31\n",
      "Round:     173 \tEpsilon:  0.70 \tTest Score:    9.69\n",
      "Round:     174 \tEpsilon:  0.70 \tTest Score:    9.53\n",
      "Round:     175 \tEpsilon:  0.70 \tTest Score:    9.22\n",
      "Round:     176 \tEpsilon:  0.70 \tTest Score:   75.28\n",
      "Round:     177 \tEpsilon:  0.70 \tTest Score:    9.81\n",
      "Round:     178 \tEpsilon:  0.70 \tTest Score:    9.28\n",
      "Round:     179 \tEpsilon:  0.69 \tTest Score:    9.47\n",
      "Round:     180 \tEpsilon:  0.69 \tTest Score:    9.44\n",
      "Round:     181 \tEpsilon:  0.69 \tTest Score:    9.44\n",
      "Round:     182 \tEpsilon:  0.69 \tTest Score:    9.31\n",
      "Round:     183 \tEpsilon:  0.69 \tTest Score:    9.62\n",
      "Round:     184 \tEpsilon:  0.69 \tTest Score:    9.22\n",
      "Round:     185 \tEpsilon:  0.69 \tTest Score:    9.09\n",
      "Round:     186 \tEpsilon:  0.69 \tTest Score:    9.47\n",
      "Round:     187 \tEpsilon:  0.69 \tTest Score:    9.44\n",
      "Round:     188 \tEpsilon:  0.69 \tTest Score:    9.25\n",
      "Round:     189 \tEpsilon:  0.68 \tTest Score:    9.38\n",
      "Round:     190 \tEpsilon:  0.68 \tTest Score:    9.41\n",
      "Round:     191 \tEpsilon:  0.68 \tTest Score:    9.25\n",
      "Round:     192 \tEpsilon:  0.68 \tTest Score:    9.28\n",
      "Round:     193 \tEpsilon:  0.68 \tTest Score:    9.25\n",
      "Round:     194 \tEpsilon:  0.68 \tTest Score:    9.28\n",
      "Round:     195 \tEpsilon:  0.68 \tTest Score:    9.44\n",
      "Round:     196 \tEpsilon:  0.68 \tTest Score:    9.34\n",
      "Round:     197 \tEpsilon:  0.68 \tTest Score:   23.78\n",
      "Round:     198 \tEpsilon:  0.67 \tTest Score:   15.69\n",
      "Round:     199 \tEpsilon:  0.67 \tTest Score:   12.34\n",
      "Round:     200 \tEpsilon:  0.67 \tTest Score:  160.59\n",
      "Round:     201 \tEpsilon:  0.67 \tTest Score:   66.78\n",
      "Round:     202 \tEpsilon:  0.67 \tTest Score:   72.38\n",
      "Round:     203 \tEpsilon:  0.67 \tTest Score:   76.62\n",
      "Round:     204 \tEpsilon:  0.66 \tTest Score:   84.88\n",
      "Round:     205 \tEpsilon:  0.66 \tTest Score:   87.31\n",
      "Round:     206 \tEpsilon:  0.66 \tTest Score:   89.56\n",
      "Round:     207 \tEpsilon:  0.66 \tTest Score:   86.47\n",
      "Round:     208 \tEpsilon:  0.66 \tTest Score:   38.53\n",
      "Round:     209 \tEpsilon:  0.65 \tTest Score:   30.25\n",
      "Round:     210 \tEpsilon:  0.65 \tTest Score:   25.00\n",
      "Round:     211 \tEpsilon:  0.65 \tTest Score:   23.78\n",
      "Round:     212 \tEpsilon:  0.65 \tTest Score:   26.16\n",
      "Round:     213 \tEpsilon:  0.65 \tTest Score:   27.41\n",
      "Round:     214 \tEpsilon:  0.64 \tTest Score:   28.50\n",
      "Round:     215 \tEpsilon:  0.64 \tTest Score:   28.16\n",
      "Round:     216 \tEpsilon:  0.64 \tTest Score:   29.31\n",
      "Round:     217 \tEpsilon:  0.64 \tTest Score:   26.66\n",
      "Round:     218 \tEpsilon:  0.64 \tTest Score:   27.53\n",
      "Round:     219 \tEpsilon:  0.63 \tTest Score:   25.19\n",
      "Round:     220 \tEpsilon:  0.63 \tTest Score:   25.69\n",
      "Round:     221 \tEpsilon:  0.63 \tTest Score:   27.50\n",
      "Round:     222 \tEpsilon:  0.63 \tTest Score:   27.97\n",
      "Round:     223 \tEpsilon:  0.63 \tTest Score:   28.47\n",
      "Round:     224 \tEpsilon:  0.63 \tTest Score:   29.53\n",
      "Round:     225 \tEpsilon:  0.62 \tTest Score:   35.91\n",
      "Round:     226 \tEpsilon:  0.62 \tTest Score:   35.22\n",
      "Round:     227 \tEpsilon:  0.61 \tTest Score:   45.78\n",
      "Round:     228 \tEpsilon:  0.61 \tTest Score:   42.94\n",
      "Round:     229 \tEpsilon:  0.61 \tTest Score:   50.97\n",
      "Round:     230 \tEpsilon:  0.61 \tTest Score:   53.09\n",
      "Round:     231 \tEpsilon:  0.61 \tTest Score:   57.41\n",
      "Round:     232 \tEpsilon:  0.60 \tTest Score:   47.34\n",
      "Round:     233 \tEpsilon:  0.60 \tTest Score:   47.78\n",
      "Round:     234 \tEpsilon:  0.60 \tTest Score:   59.69\n",
      "Round:     235 \tEpsilon:  0.59 \tTest Score:   60.75\n",
      "Round:     236 \tEpsilon:  0.59 \tTest Score:   61.81\n",
      "Round:     237 \tEpsilon:  0.59 \tTest Score:   76.16\n",
      "Round:     238 \tEpsilon:  0.59 \tTest Score:   74.56\n",
      "Round:     239 \tEpsilon:  0.59 \tTest Score:   69.88\n",
      "Round:     240 \tEpsilon:  0.58 \tTest Score:   78.12\n",
      "Round:     241 \tEpsilon:  0.58 \tTest Score:   62.72\n",
      "Round:     242 \tEpsilon:  0.58 \tTest Score:   63.75\n",
      "Round:     243 \tEpsilon:  0.58 \tTest Score:   65.38\n",
      "Round:     244 \tEpsilon:  0.57 \tTest Score:   52.34\n",
      "Round:     245 \tEpsilon:  0.57 \tTest Score:   58.50\n",
      "Round:     246 \tEpsilon:  0.57 \tTest Score:   62.91\n",
      "Round:     247 \tEpsilon:  0.57 \tTest Score:   64.72\n",
      "Round:     248 \tEpsilon:  0.57 \tTest Score:   61.56\n",
      "Round:     249 \tEpsilon:  0.56 \tTest Score:   66.06\n",
      "Round:     250 \tEpsilon:  0.56 \tTest Score:   73.03\n",
      "Round:     251 \tEpsilon:  0.56 \tTest Score:   81.75\n",
      "Round:     252 \tEpsilon:  0.55 \tTest Score:   91.19\n",
      "Round:     253 \tEpsilon:  0.55 \tTest Score:   84.22\n",
      "Round:     254 \tEpsilon:  0.54 \tTest Score:   74.75\n",
      "Round:     255 \tEpsilon:  0.54 \tTest Score:   79.72\n",
      "Round:     256 \tEpsilon:  0.54 \tTest Score:   80.31\n",
      "Round:     257 \tEpsilon:  0.54 \tTest Score:   74.19\n",
      "Round:     258 \tEpsilon:  0.54 \tTest Score:   76.81\n",
      "Round:     259 \tEpsilon:  0.53 \tTest Score:   83.09\n",
      "Round:     260 \tEpsilon:  0.53 \tTest Score:   72.03\n",
      "Round:     261 \tEpsilon:  0.53 \tTest Score:   65.62\n",
      "Round:     262 \tEpsilon:  0.53 \tTest Score:   66.94\n",
      "Round:     263 \tEpsilon:  0.52 \tTest Score:   88.41\n",
      "Round:     264 \tEpsilon:  0.51 \tTest Score:   83.78\n",
      "Round:     265 \tEpsilon:  0.51 \tTest Score:   94.41\n",
      "Round:     266 \tEpsilon:  0.51 \tTest Score:   78.56\n",
      "Round:     267 \tEpsilon:  0.50 \tTest Score:   87.97\n",
      "Round:     268 \tEpsilon:  0.50 \tTest Score:   85.72\n",
      "Round:     269 \tEpsilon:  0.50 \tTest Score:   77.06\n",
      "Round:     270 \tEpsilon:  0.50 \tTest Score:   81.81\n",
      "Round:     271 \tEpsilon:  0.50 \tTest Score:   76.06\n",
      "Round:     272 \tEpsilon:  0.49 \tTest Score:   82.44\n",
      "Round:     273 \tEpsilon:  0.49 \tTest Score:  103.38\n",
      "Round:     274 \tEpsilon:  0.49 \tTest Score:  113.09\n",
      "Round:     275 \tEpsilon:  0.48 \tTest Score:   89.22\n",
      "Round:     276 \tEpsilon:  0.48 \tTest Score:   73.50\n",
      "Round:     277 \tEpsilon:  0.48 \tTest Score:   73.56\n",
      "Round:     278 \tEpsilon:  0.48 \tTest Score:   86.69\n",
      "Round:     279 \tEpsilon:  0.47 \tTest Score:  102.06\n",
      "Round:     280 \tEpsilon:  0.47 \tTest Score:   99.19\n",
      "Round:     281 \tEpsilon:  0.47 \tTest Score:  107.66\n",
      "Round:     282 \tEpsilon:  0.46 \tTest Score:  171.19\n",
      "Round:     283 \tEpsilon:  0.46 \tTest Score:   76.78\n",
      "Round:     284 \tEpsilon:  0.46 \tTest Score:   67.41\n",
      "Round:     285 \tEpsilon:  0.46 \tTest Score:   79.84\n",
      "Round:     286 \tEpsilon:  0.45 \tTest Score:   70.16\n",
      "Round:     287 \tEpsilon:  0.45 \tTest Score:   65.38\n",
      "Round:     288 \tEpsilon:  0.45 \tTest Score:   72.25\n",
      "Round:     289 \tEpsilon:  0.45 \tTest Score:   82.00\n",
      "Round:     290 \tEpsilon:  0.44 \tTest Score:  106.44\n",
      "Round:     291 \tEpsilon:  0.44 \tTest Score:  111.97\n",
      "Round:     292 \tEpsilon:  0.43 \tTest Score:   97.94\n",
      "Round:     293 \tEpsilon:  0.43 \tTest Score:   95.91\n",
      "Round:     294 \tEpsilon:  0.43 \tTest Score:   87.88\n",
      "Round:     295 \tEpsilon:  0.43 \tTest Score:  102.69\n",
      "Round:     296 \tEpsilon:  0.42 \tTest Score:  101.81\n",
      "Round:     297 \tEpsilon:  0.42 \tTest Score:  115.12\n",
      "Round:     298 \tEpsilon:  0.42 \tTest Score:  120.81\n",
      "Round:     299 \tEpsilon:  0.42 \tTest Score:  110.91\n",
      "Round:     300 \tEpsilon:  0.41 \tTest Score:   95.75\n",
      "Round:     301 \tEpsilon:  0.41 \tTest Score:  137.94\n",
      "Round:     302 \tEpsilon:  0.40 \tTest Score:  129.47\n",
      "Round:     303 \tEpsilon:  0.40 \tTest Score:  172.56\n",
      "Round:     304 \tEpsilon:  0.40 \tTest Score:  172.28\n",
      "Round:     305 \tEpsilon:  0.39 \tTest Score:   89.34\n",
      "Round:     306 \tEpsilon:  0.39 \tTest Score:  103.59\n",
      "Round:     307 \tEpsilon:  0.39 \tTest Score:   90.56\n",
      "Round:     308 \tEpsilon:  0.38 \tTest Score:   74.41\n",
      "Round:     309 \tEpsilon:  0.38 \tTest Score:   69.66\n",
      "Round:     310 \tEpsilon:  0.38 \tTest Score:   83.25\n",
      "Round:     311 \tEpsilon:  0.38 \tTest Score:   93.97\n",
      "Round:     312 \tEpsilon:  0.37 \tTest Score:  130.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:     313 \tEpsilon:  0.37 \tTest Score:  116.81\n",
      "Round:     314 \tEpsilon:  0.36 \tTest Score:  170.44\n",
      "Round:     315 \tEpsilon:  0.36 \tTest Score:  167.34\n",
      "Round:     316 \tEpsilon:  0.36 \tTest Score:  167.78\n",
      "Round:     317 \tEpsilon:  0.36 \tTest Score:  101.03\n",
      "Round:     318 \tEpsilon:  0.35 \tTest Score:  115.00\n",
      "Round:     319 \tEpsilon:  0.35 \tTest Score:  124.62\n",
      "Round:     320 \tEpsilon:  0.35 \tTest Score:  149.12\n",
      "Round:     321 \tEpsilon:  0.35 \tTest Score:  168.16\n",
      "Round:     322 \tEpsilon:  0.34 \tTest Score:   71.84\n",
      "Round:     323 \tEpsilon:  0.34 \tTest Score:  169.25\n",
      "Round:     324 \tEpsilon:  0.34 \tTest Score:  136.03\n",
      "Round:     325 \tEpsilon:  0.34 \tTest Score:   95.25\n",
      "Round:     326 \tEpsilon:  0.33 \tTest Score:  100.25\n",
      "Round:     327 \tEpsilon:  0.33 \tTest Score:   87.28\n",
      "Round:     328 \tEpsilon:  0.33 \tTest Score:  149.72\n",
      "Round:     329 \tEpsilon:  0.32 \tTest Score:  143.12\n",
      "Round:     330 \tEpsilon:  0.32 \tTest Score:  114.16\n",
      "Round:     331 \tEpsilon:  0.32 \tTest Score:  128.59\n",
      "Round:     332 \tEpsilon:  0.32 \tTest Score:  170.09\n",
      "Round:     333 \tEpsilon:  0.31 \tTest Score:  139.34\n",
      "Round:     334 \tEpsilon:  0.31 \tTest Score:  112.47\n",
      "Round:     335 \tEpsilon:  0.31 \tTest Score:  163.16\n",
      "Round:     336 \tEpsilon:  0.30 \tTest Score:  113.81\n",
      "Round:     337 \tEpsilon:  0.30 \tTest Score:  129.09\n",
      "Round:     338 \tEpsilon:  0.30 \tTest Score:  139.97\n",
      "Round:     339 \tEpsilon:  0.29 \tTest Score:   94.62\n",
      "Round:     340 \tEpsilon:  0.29 \tTest Score:  160.09\n",
      "Round:     341 \tEpsilon:  0.29 \tTest Score:  172.50\n",
      "Round:     342 \tEpsilon:  0.29 \tTest Score:  111.69\n",
      "Round:     343 \tEpsilon:  0.28 \tTest Score:  128.81\n",
      "Round:     344 \tEpsilon:  0.28 \tTest Score:  102.81\n",
      "Round:     345 \tEpsilon:  0.28 \tTest Score:  166.38\n",
      "Round:     346 \tEpsilon:  0.28 \tTest Score:  124.00\n",
      "Round:     347 \tEpsilon:  0.27 \tTest Score:  132.19\n",
      "Round:     348 \tEpsilon:  0.27 \tTest Score:  180.72\n",
      "Round:     349 \tEpsilon:  0.27 \tTest Score:  161.19\n",
      "Round:     350 \tEpsilon:  0.27 \tTest Score:  161.38\n",
      "Round:     351 \tEpsilon:  0.26 \tTest Score:  143.09\n",
      "Round:     352 \tEpsilon:  0.26 \tTest Score:  154.75\n",
      "Round:     353 \tEpsilon:  0.26 \tTest Score:   94.72\n",
      "Round:     354 \tEpsilon:  0.26 \tTest Score:   82.84\n",
      "Round:     355 \tEpsilon:  0.26 \tTest Score:  185.91\n",
      "Round:     356 \tEpsilon:  0.25 \tTest Score:  173.38\n",
      "Round:     357 \tEpsilon:  0.25 \tTest Score:  167.84\n",
      "Round:     358 \tEpsilon:  0.25 \tTest Score:   99.97\n",
      "Round:     359 \tEpsilon:  0.25 \tTest Score:  121.56\n",
      "Round:     360 \tEpsilon:  0.24 \tTest Score:  109.94\n",
      "Round:     361 \tEpsilon:  0.24 \tTest Score:  137.22\n",
      "Round:     362 \tEpsilon:  0.24 \tTest Score:  169.34\n",
      "Round:     363 \tEpsilon:  0.24 \tTest Score:  139.88\n",
      "Round:     364 \tEpsilon:  0.24 \tTest Score:  168.31\n",
      "Round:     365 \tEpsilon:  0.23 \tTest Score:  158.41\n",
      "Round:     366 \tEpsilon:  0.23 \tTest Score:  161.81\n",
      "Round:     367 \tEpsilon:  0.23 \tTest Score:  138.69\n",
      "Round:     368 \tEpsilon:  0.23 \tTest Score:  165.22\n",
      "Round:     369 \tEpsilon:  0.22 \tTest Score:  173.66\n",
      "Round:     370 \tEpsilon:  0.22 \tTest Score:  161.25\n",
      "Round:     371 \tEpsilon:  0.22 \tTest Score:  180.97\n",
      "Round:     372 \tEpsilon:  0.22 \tTest Score:  167.47\n",
      "Round:     373 \tEpsilon:  0.21 \tTest Score:  150.84\n",
      "Round:     374 \tEpsilon:  0.21 \tTest Score:  162.25\n",
      "Round:     375 \tEpsilon:  0.21 \tTest Score:  134.12\n",
      "Round:     376 \tEpsilon:  0.21 \tTest Score:  123.22\n",
      "Round:     377 \tEpsilon:  0.20 \tTest Score:  121.75\n",
      "Round:     378 \tEpsilon:  0.20 \tTest Score:  157.47\n",
      "Round:     379 \tEpsilon:  0.20 \tTest Score:  179.22\n",
      "Round:     380 \tEpsilon:  0.19 \tTest Score:  162.22\n",
      "Round:     381 \tEpsilon:  0.19 \tTest Score:  183.66\n",
      "Round:     382 \tEpsilon:  0.19 \tTest Score:  174.47\n",
      "Round:     383 \tEpsilon:  0.19 \tTest Score:  119.00\n",
      "Round:     384 \tEpsilon:  0.19 \tTest Score:  135.59\n",
      "Round:     385 \tEpsilon:  0.18 \tTest Score:  126.84\n",
      "Round:     386 \tEpsilon:  0.18 \tTest Score:  143.56\n",
      "Round:     387 \tEpsilon:  0.18 \tTest Score:  137.72\n",
      "Round:     388 \tEpsilon:  0.18 \tTest Score:  174.94\n",
      "Round:     389 \tEpsilon:  0.17 \tTest Score:  166.75\n",
      "Round:     390 \tEpsilon:  0.17 \tTest Score:  123.16\n",
      "Round:     391 \tEpsilon:  0.17 \tTest Score:  119.81\n",
      "Round:     392 \tEpsilon:  0.17 \tTest Score:  140.06\n",
      "Round:     393 \tEpsilon:  0.17 \tTest Score:  121.34\n",
      "Round:     394 \tEpsilon:  0.16 \tTest Score:  120.25\n",
      "Round:     395 \tEpsilon:  0.16 \tTest Score:  129.19\n",
      "Round:     396 \tEpsilon:  0.16 \tTest Score:  131.34\n",
      "Round:     397 \tEpsilon:  0.15 \tTest Score:  142.78\n",
      "Round:     398 \tEpsilon:  0.15 \tTest Score:  118.94\n",
      "Round:     399 \tEpsilon:  0.15 \tTest Score:  137.22\n",
      "Round:     400 \tEpsilon:  0.15 \tTest Score:  134.84\n",
      "Round:     401 \tEpsilon:  0.15 \tTest Score:  115.22\n",
      "Round:     402 \tEpsilon:  0.15 \tTest Score:  138.69\n",
      "Round:     403 \tEpsilon:  0.14 \tTest Score:  126.41\n",
      "Round:     404 \tEpsilon:  0.14 \tTest Score:  127.56\n",
      "Round:     405 \tEpsilon:  0.14 \tTest Score:  130.56\n",
      "Round:     406 \tEpsilon:  0.14 \tTest Score:  174.22\n",
      "Round:     407 \tEpsilon:  0.14 \tTest Score:  142.94\n",
      "Round:     408 \tEpsilon:  0.13 \tTest Score:  177.50\n",
      "Round:     409 \tEpsilon:  0.13 \tTest Score:  145.75\n",
      "Round:     410 \tEpsilon:  0.13 \tTest Score:  192.38\n",
      "Round:     411 \tEpsilon:  0.13 \tTest Score:  177.53\n",
      "Round:     412 \tEpsilon:  0.13 \tTest Score:  193.53\n",
      "Round:     413 \tEpsilon:  0.12 \tTest Score:  190.78\n",
      "Round:     414 \tEpsilon:  0.12 \tTest Score:  184.84\n",
      "Round:     415 \tEpsilon:  0.12 \tTest Score:  196.81\n",
      "Round:     416 \tEpsilon:  0.12 \tTest Score:  198.41\n",
      "Round:     417 \tEpsilon:  0.12 \tTest Score:  197.81\n",
      "Round:     418 \tEpsilon:  0.11 \tTest Score:  197.91\n",
      "Round:     419 \tEpsilon:  0.11 \tTest Score:  199.81\n",
      "Round:     420 \tEpsilon:  0.11 \tTest Score:  195.94\n",
      "Round:     421 \tEpsilon:  0.11 \tTest Score:  182.44\n",
      "Round:     422 \tEpsilon:  0.11 \tTest Score:  190.56\n",
      "Round:     423 \tEpsilon:  0.10 \tTest Score:  198.72\n",
      "Round:     424 \tEpsilon:  0.10 \tTest Score:  198.31\n",
      "Round:     425 \tEpsilon:  0.10 \tTest Score:  196.91\n",
      "Round:     426 \tEpsilon:  0.10 \tTest Score:  197.84\n",
      "Round:     427 \tEpsilon:  0.10 \tTest Score:  197.94\n",
      "Round:     428 \tEpsilon:  0.10 \tTest Score:  197.94\n",
      "Round:     429 \tEpsilon:  0.09 \tTest Score:  199.88\n",
      "Round:     430 \tEpsilon:  0.09 \tTest Score:  200.00\n",
      "Round:     431 \tEpsilon:  0.09 \tTest Score:  200.00\n",
      "Round:     432 \tEpsilon:  0.09 \tTest Score:  200.00\n",
      "Round:     433 \tEpsilon:  0.09 \tTest Score:  200.00\n",
      "Round:     434 \tEpsilon:  0.09 \tTest Score:  200.00\n",
      "Round:     435 \tEpsilon:  0.08 \tTest Score:  200.00\n",
      "Round:     436 \tEpsilon:  0.08 \tTest Score:  197.41\n",
      "Round:     437 \tEpsilon:  0.08 \tTest Score:  199.44\n",
      "Round:     438 \tEpsilon:  0.08 \tTest Score:  200.00\n",
      "Round:     439 \tEpsilon:  0.08 \tTest Score:  200.00\n",
      "Round:     440 \tEpsilon:  0.08 \tTest Score:  200.00\n",
      "Round:     441 \tEpsilon:  0.08 \tTest Score:  200.00\n",
      "Round:     442 \tEpsilon:  0.07 \tTest Score:  200.00\n",
      "Round:     443 \tEpsilon:  0.07 \tTest Score:  200.00\n",
      "Round:     444 \tEpsilon:  0.07 \tTest Score:  200.00\n",
      "Round:     445 \tEpsilon:  0.07 \tTest Score:  200.00\n",
      "Round:     446 \tEpsilon:  0.07 \tTest Score:  200.00\n",
      "Round:     447 \tEpsilon:  0.07 \tTest Score:  200.00\n",
      "Round:     448 \tEpsilon:  0.07 \tTest Score:  200.00\n",
      "Round:     449 \tEpsilon:  0.07 \tTest Score:  200.00\n",
      "Round:     450 \tEpsilon:  0.07 \tTest Score:  200.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cd7cea14cb01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreport_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Round: {0:7d} \\tEpsilon: {1:5.2f} \\tTest Score: {2:7.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-cd7cea14cb01>\u001b[0m in \u001b[0;36mtest_player\u001b[0;34m(player, env, runs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mrun_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-90f6f81f6d21>\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mQs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m#         print (\"=====================\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/DGPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/DGPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/DGPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/DGPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/DGPU/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Hyperparameters\n",
    "num_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 200                # max steps in an episode\n",
    "gamma = 0                   # future reward discount\n",
    "gamma_wait = 1000\n",
    "gamma_later = 0.99\n",
    "train_freq = 1\n",
    "target_update_freq = None\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_layer = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "buffer_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "\n",
    "# Reporting Interval\n",
    "report_freq = 1\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "# Environment Parameters\n",
    "e_size = 4\n",
    "a_size = 2\n",
    "\n",
    "\n",
    "def test_player(player, env, runs=100):\n",
    "    reward_sum = 0\n",
    "    for i in range(runs):\n",
    "        run_reward = 0\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        t = 0.\n",
    "        while not done:\n",
    "            t += 1\n",
    "            action = player.choose_action(state)\n",
    "            state, reward, done, info = env.step(action)\n",
    "            run_reward += reward\n",
    "            if done:\n",
    "                reward_sum += run_reward\n",
    "                break\n",
    "        env.reset()\n",
    "    return reward_sum/runs\n",
    "\n",
    "\n",
    "\n",
    "step_count = 0\n",
    "scores = []\n",
    "sess = tf.Session()\n",
    "\n",
    "# Create Agent\n",
    "player = DQN(sess, e_size, hidden_layer, a_size, learning_rate, gamma, buffer_size, batch_size)\n",
    "\n",
    "# Initialize \n",
    "sess.run(tf.global_variables_initializer())\n",
    "player.update_target()\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    t = 0\n",
    "    while not done:\n",
    "        step_count += 1\n",
    "        t += 1\n",
    "        # Epsilon greedy exploration policy\n",
    "        epsilon = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step_count) \n",
    "        if (np.random.uniform() <= epsilon):\n",
    "            # Make a random action\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = player.choose_action(state)\n",
    "            # Do a weighted sample to pick your action\n",
    "#             action_prob = player.choose_probs(state)[0]\n",
    "# #                 print (action_prob)\n",
    "#             action = np.random.choice(range(a_size), p=action_prob)\n",
    "\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "#         reward = 0 if done else 1\n",
    "        \n",
    "        player.remember(state, action, reward, done, new_state)\n",
    "        state = new_state\n",
    "        \n",
    "        if (step_count == gamma_wait):\n",
    "            print(\"Activate!\")\n",
    "            gamma = gamma_later\n",
    "\n",
    "        if (step_count % train_freq == 0):\n",
    "            player.train(gamma)\n",
    "\n",
    "        if (target_update_freq is not None and step_count % target_update_freq == 0):\n",
    "            print (\"updating target\")\n",
    "            player.update_target()\n",
    "\n",
    "        if done:\n",
    "\n",
    "            if (i % report_freq == 0 or i == num_episodes-1):\n",
    "                score = test_player(player, env, runs=32)\n",
    "                scores.append(score)\n",
    "                print(\"Round: {0:7d} \\tEpsilon: {1:5.2f} \\tTest Score: {2:7.2f}\".format(i, epsilon, score))\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DGPU]",
   "language": "python",
   "name": "conda-env-DGPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
